{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import random\n",
    "from transformers import AdamW, AutoTokenizer, AutoModel, DataCollatorWithPadding, AutoConfig\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "import math\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from sklearn.model_selection import KFold\n",
    "import urllib.request\n",
    "from typing import List\n",
    "from functools import partial\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GroupKFold, KFold\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers.models.deberta.modeling_deberta import ContextPooler\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "import scipy.sparse as sp\n",
    "from math import log\n",
    "import string # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('feedback-prize-effectiveness/train.csv')\n",
    "test = pd.read_csv('feedback-prize-effectiveness/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"feedback-prize-effectiveness/train\"\n",
    "TEST_DIR = \"feedback-prize-effectiveness/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_get_essay(essay_id):\n",
    "    essay_path = os.path.join(TRAIN_DIR, f\"{essay_id}.txt\")\n",
    "    essay_text = open(essay_path, 'r').read()\n",
    "    return essay_text\n",
    "def test_get_essay(essay_id):\n",
    "    essay_path = os.path.join(TEST_DIR, f\"{essay_id}.txt\")\n",
    "    essay_text = open(essay_path, 'r').read()\n",
    "    return essay_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['essay_text'] = train['essay_id'].apply(train_get_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['essay_text'] = test['essay_id'].apply(test_get_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>essay_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36760</th>\n",
       "      <td>9f63b687e76a</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>For many people they don't like only asking on...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Some people may ask multiple people for advice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36761</th>\n",
       "      <td>9d5bd7d86212</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>also people have different views and opinions ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Some people may ask multiple people for advice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36762</th>\n",
       "      <td>f1b78becd573</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>Advice is something that can impact a persons ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Some people may ask multiple people for advice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36763</th>\n",
       "      <td>cc184624ca8e</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>someone can use everything that many people sa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>Some people may ask multiple people for advice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36764</th>\n",
       "      <td>c8a973681feb</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>In conclusion asking for an opinion can be ben...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>Some people may ask multiple people for advice...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36765 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       discourse_id      essay_id  \\\n",
       "0      0013cc385424  007ACE74B050   \n",
       "1      9704a709b505  007ACE74B050   \n",
       "2      c22adee811b6  007ACE74B050   \n",
       "3      a10d361e54e4  007ACE74B050   \n",
       "4      db3e453ec4e2  007ACE74B050   \n",
       "...             ...           ...   \n",
       "36760  9f63b687e76a  FFA381E58FC6   \n",
       "36761  9d5bd7d86212  FFA381E58FC6   \n",
       "36762  f1b78becd573  FFA381E58FC6   \n",
       "36763  cc184624ca8e  FFA381E58FC6   \n",
       "36764  c8a973681feb  FFA381E58FC6   \n",
       "\n",
       "                                          discourse_text  \\\n",
       "0      Hi, i'm Isaac, i'm going to be writing about h...   \n",
       "1      On my perspective, I think that the face is a ...   \n",
       "2      I think that the face is a natural landform be...   \n",
       "3      If life was on Mars, we would know by now. The...   \n",
       "4      People thought that the face was formed by ali...   \n",
       "...                                                  ...   \n",
       "36760  For many people they don't like only asking on...   \n",
       "36761  also people have different views and opinions ...   \n",
       "36762  Advice is something that can impact a persons ...   \n",
       "36763  someone can use everything that many people sa...   \n",
       "36764  In conclusion asking for an opinion can be ben...   \n",
       "\n",
       "             discourse_type discourse_effectiveness  \\\n",
       "0                      Lead                Adequate   \n",
       "1                  Position                Adequate   \n",
       "2                     Claim                Adequate   \n",
       "3                  Evidence                Adequate   \n",
       "4              Counterclaim                Adequate   \n",
       "...                     ...                     ...   \n",
       "36760                 Claim                Adequate   \n",
       "36761                 Claim                Adequate   \n",
       "36762              Position                Adequate   \n",
       "36763              Evidence             Ineffective   \n",
       "36764  Concluding Statement             Ineffective   \n",
       "\n",
       "                                              essay_text  \n",
       "0      Hi, i'm Isaac, i'm going to be writing about h...  \n",
       "1      Hi, i'm Isaac, i'm going to be writing about h...  \n",
       "2      Hi, i'm Isaac, i'm going to be writing about h...  \n",
       "3      Hi, i'm Isaac, i'm going to be writing about h...  \n",
       "4      Hi, i'm Isaac, i'm going to be writing about h...  \n",
       "...                                                  ...  \n",
       "36760  Some people may ask multiple people for advice...  \n",
       "36761  Some people may ask multiple people for advice...  \n",
       "36762  Some people may ask multiple people for advice...  \n",
       "36763  Some people may ask multiple people for advice...  \n",
       "36764  Some people may ask multiple people for advice...  \n",
       "\n",
       "[36765 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['text'] = train['discourse_text'] + \" \" + train['discourse_type'] + \" \" + train['essay_text']\n",
    "test['text'] = test['discourse_text'] + \" \" + test['discourse_type'] + \" \" + test['essay_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings_dim = 300\n",
    "word_vector_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lst = []\n",
    "test_lst = []\n",
    "for x in train['text']:\n",
    "    train_lst.append(x)\n",
    "for x in test['text']:\n",
    "    test_lst.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_graph(shuffle_doc_words_lst):\n",
    "    # build vocab\n",
    "    word_freq = {}\n",
    "    word_set = set()\n",
    "    for doc_words in tqdm(shuffle_doc_words_list):\n",
    "        words = doc_words.split()\n",
    "        for word in words:\n",
    "            word_set.add(word)\n",
    "            if word in word_freq:\n",
    "                word_freq[word] += 1\n",
    "            else:\n",
    "                word_freq[word] = 1\n",
    "\n",
    "    vocab = list(word_set)\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    word_doc_list = {}\n",
    "\n",
    "    for i in tqdm(range(len(shuffle_doc_words_list))):\n",
    "        doc_words = shuffle_doc_words_list[i]\n",
    "        words = doc_words.split()\n",
    "        appeared = set()\n",
    "        for word in words:\n",
    "            if word in appeared:\n",
    "                continue\n",
    "            if word in word_doc_list:\n",
    "                doc_list = word_doc_list[word]\n",
    "                doc_list.append(i)\n",
    "                word_doc_list[word] = doc_list\n",
    "            else:\n",
    "                word_doc_list[word] = [i]\n",
    "            appeared.add(word)\n",
    "\n",
    "    word_doc_freq = {}\n",
    "    for word, doc_list in word_doc_list.items():\n",
    "        word_doc_freq[word] = len(doc_list)\n",
    "\n",
    "    word_id_map = {}\n",
    "    for i in range(vocab_size):\n",
    "        word_id_map[vocab[i]] = i\n",
    "\n",
    "    len(word_doc_freq)\n",
    "\n",
    "    row_x = []\n",
    "    col_x = []\n",
    "    data_x = []\n",
    "    for i in tqdm(range(len(shuffle_doc_words_list))):\n",
    "        doc_vec = np.array([0.0 for k in range(word_embeddings_dim)])\n",
    "        doc_words = shuffle_doc_words_list[i]\n",
    "        words = doc_words.split()\n",
    "        doc_len = len(words)\n",
    "        for word in words:\n",
    "            if word in word_vector_map:\n",
    "                word_vector = word_vector_map[word]\n",
    "                # print(doc_vec)\n",
    "                # print(np.array(word_vector))\n",
    "                doc_vec = doc_vec + np.array(word_vector)\n",
    "\n",
    "        for j in range(word_embeddings_dim):\n",
    "            row_x.append(i)\n",
    "            col_x.append(j)\n",
    "            # np.random.uniform(-0.25, 0.25)\n",
    "            data_x.append(doc_vec[j] / doc_len)  # doc_vec[j]/ doc_len\n",
    "\n",
    "    x = sp.csr_matrix((data_x, (row_x, col_x)), shape=(\n",
    "        len(shuffle_doc_words_list), word_embeddings_dim))\n",
    "\n",
    "    # y = []\n",
    "    # for i in range(len(train['text'])):\n",
    "    #     doc_meta = train['text'][i]\n",
    "    #     temp = doc_meta.split('\\t')\n",
    "    #     label = temp[2]\n",
    "    #     one_hot = [0 for l in range(len(label_list))]\n",
    "    #     label_index = label_list.index(label)\n",
    "    #     one_hot[label_index] = 1\n",
    "    #     y.append(one_hot)\n",
    "    # y = np.array(y)\n",
    "    # print(y)\n",
    "\n",
    "    window_size = 20\n",
    "    windows = []\n",
    "\n",
    "    for doc_words in tqdm(shuffle_doc_words_list):\n",
    "        words = doc_words.split()\n",
    "        length = len(words)\n",
    "        if length <= window_size:\n",
    "            windows.append(words)\n",
    "        else:\n",
    "            # print(length, length - window_size + 1)\n",
    "            for j in range(length - window_size + 1):\n",
    "                window = words[j: j + window_size]\n",
    "                windows.append(window)\n",
    "                # print(window)\n",
    "\n",
    "    word_window_freq = {}\n",
    "    for window in tqdm(windows):\n",
    "        appeared = set()\n",
    "        for i in range(len(window)):\n",
    "            if window[i] in appeared:\n",
    "                continue\n",
    "            if window[i] in word_window_freq:\n",
    "                word_window_freq[window[i]] += 1\n",
    "            else:\n",
    "                word_window_freq[window[i]] = 1\n",
    "            appeared.add(window[i])\n",
    "\n",
    "    word_pair_count = {}\n",
    "    for window in tqdm(windows):\n",
    "        for i in range(1, len(window)):\n",
    "            for j in range(0, i):\n",
    "                word_i = window[i]\n",
    "                word_i_id = word_id_map[word_i]\n",
    "                word_j = window[j]\n",
    "                word_j_id = word_id_map[word_j]\n",
    "                if word_i_id == word_j_id:\n",
    "                    continue\n",
    "                word_pair_str = str(word_i_id) + ',' + str(word_j_id)\n",
    "                if word_pair_str in word_pair_count:\n",
    "                    word_pair_count[word_pair_str] += 1\n",
    "                else:\n",
    "                    word_pair_count[word_pair_str] = 1\n",
    "                # two orders\n",
    "                word_pair_str = str(word_j_id) + ',' + str(word_i_id)\n",
    "                if word_pair_str in word_pair_count:\n",
    "                    word_pair_count[word_pair_str] += 1\n",
    "                else:\n",
    "                    word_pair_count[word_pair_str] = 1\n",
    "\n",
    "    row = []\n",
    "    col = []\n",
    "    weight = []\n",
    "    # train_size = len(train['text'])\n",
    "    train_size = len(shuffle_doc_words_list)\n",
    "    # pmi as weights\n",
    "\n",
    "    num_window = len(windows)\n",
    "\n",
    "    for key in word_pair_count:\n",
    "        temp = key.split(',')\n",
    "        i = int(temp[0])\n",
    "        j = int(temp[1])\n",
    "        count = word_pair_count[key]\n",
    "        word_freq_i = word_window_freq[vocab[i]]\n",
    "        word_freq_j = word_window_freq[vocab[j]]\n",
    "        pmi = log((1.0 * count / num_window) /\n",
    "                  (1.0 * word_freq_i * word_freq_j/(num_window * num_window)))\n",
    "        if pmi <= 0:\n",
    "            continue\n",
    "        row.append(train_size + i)\n",
    "        col.append(train_size + j)\n",
    "        weight.append(pmi)\n",
    "\n",
    "    doc_word_freq = {}\n",
    "\n",
    "    for doc_id in tqdm(range(len(shuffle_doc_words_list))):\n",
    "        doc_words = shuffle_doc_words_list[doc_id]\n",
    "        words = doc_words.split()\n",
    "        for word in words:\n",
    "            word_id = word_id_map[word]\n",
    "            doc_word_str = str(doc_id) + ',' + str(word_id)\n",
    "            if doc_word_str in doc_word_freq:\n",
    "                doc_word_freq[doc_word_str] += 1\n",
    "            else:\n",
    "                doc_word_freq[doc_word_str] = 1\n",
    "\n",
    "    for i in tqdm(range(len(shuffle_doc_words_list))):\n",
    "        doc_words = shuffle_doc_words_list[i]\n",
    "        words = doc_words.split()\n",
    "        doc_word_set = set()\n",
    "        for word in words:\n",
    "            if word in doc_word_set:\n",
    "                continue\n",
    "            j = word_id_map[word]\n",
    "            key = str(i) + ',' + str(j)\n",
    "            freq = doc_word_freq[key]\n",
    "            if i < train_size:\n",
    "                row.append(i)\n",
    "            else:\n",
    "                row.append(i + vocab_size)\n",
    "            col.append(train_size + j)\n",
    "            idf = log(1.0 * len(shuffle_doc_words_list) /\n",
    "                      word_doc_freq[vocab[j]])\n",
    "            weight.append(freq * idf)\n",
    "            doc_word_set.add(word)\n",
    "\n",
    "    node_size = train_size + vocab_size\n",
    "    adj = sp.csr_matrix(\n",
    "        (weight, (row, col)), shape=(node_size, node_size))\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = build_graph(train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"train_adj\", data=adj.data, indices=adj.indices,\n",
    "             indptr=adj.indptr, shape=adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 5008.72it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 5016.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 3341.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 5026.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4420/4420 [00:00<00:00, 86896.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4420/4420 [00:01<00:00, 3651.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 3344.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 2506.76it/s]\n"
     ]
    }
   ],
   "source": [
    "adj2 = build_graph(test_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"test_adj\", data=adj2.data, indices=adj2.indices,\n",
    "             indptr=adj2.indptr, shape=adj2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
