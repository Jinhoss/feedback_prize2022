{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport os\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\nimport torch\nfrom torch import nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler\nimport random\nfrom transformers import AdamW, AutoTokenizer, AutoModel\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler\nfrom sklearn.model_selection import train_test_split\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\nimport math\nfrom torch.optim import Adam\nfrom sklearn.model_selection import KFold\nimport urllib.request\nfrom typing import List\nfrom functools import partial\nfrom sklearn.model_selection import StratifiedShuffleSplit, GroupKFold, KFold\n\n\nimport torchmetrics\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-10T10:33:34.193233Z","iopub.execute_input":"2022-06-10T10:33:34.193661Z","iopub.status.idle":"2022-06-10T10:33:34.204114Z","shell.execute_reply.started":"2022-06-10T10:33:34.193626Z","shell.execute_reply":"2022-06-10T10:33:34.202774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:34.206408Z","iopub.execute_input":"2022-06-10T10:33:34.207067Z","iopub.status.idle":"2022-06-10T10:33:34.222941Z","shell.execute_reply.started":"2022-06-10T10:33:34.207022Z","shell.execute_reply":"2022-06-10T10:33:34.222025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:34.225958Z","iopub.execute_input":"2022-06-10T10:33:34.226418Z","iopub.status.idle":"2022-06-10T10:33:34.238815Z","shell.execute_reply.started":"2022-06-10T10:33:34.226374Z","shell.execute_reply":"2022-06-10T10:33:34.237939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_num = 22\nrandom.seed(seed_num)\nnp.random.seed(seed_num)\ntorch.manual_seed(seed_num)\ntorch.cuda.manual_seed_all(seed_num)\nif torch.cuda.is_available():    \n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\nelse:\n    device = torch.device(\"cpu\")\n    print('No GPU available, using the CPU instead.')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:34.240809Z","iopub.execute_input":"2022-06-10T10:33:34.241522Z","iopub.status.idle":"2022-06-10T10:33:34.251193Z","shell.execute_reply.started":"2022-06-10T10:33:34.241483Z","shell.execute_reply":"2022-06-10T10:33:34.250289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeedbackDataset(Dataset):\n    def __init__(self, data, is_train=True):\n        super().__init__()\n        self.max_length = 512\n        self.data = data\n        self.tokenizer = AutoTokenizer.from_pretrained('../input/deberta-v3-base/deberta-v3-base')\n        self.is_train = is_train\n    \n    def labeling(self, label):\n        new_label = {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}\n        return new_label[label]\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        if self.is_train:\n            sentence1, sentence2, label = self.data['discourse_text'][idx], self.data['discourse_type'][idx], self.data['discourse_effectiveness'][idx]\n            label = self.labeling(label)\n            label = torch.LongTensor([label])\n        else:\n            sentence1, sentence2 = self.data['discourse_text'][idx], self.data['discourse_type'][idx]\n        input_ids = self.tokenizer.encode(sentence1, sentence2, truncation=True, max_length=self.max_length, padding='max_length', truncation_strategy='only_first')\n        input_ids = torch.LongTensor(input_ids)\n        if self.is_train:\n            return input_ids, label\n        else:\n            return input_ids","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:34.253297Z","iopub.execute_input":"2022-06-10T10:33:34.254122Z","iopub.status.idle":"2022-06-10T10:33:34.266332Z","shell.execute_reply.started":"2022-06-10T10:33:34.254081Z","shell.execute_reply":"2022-06-10T10:33:34.265258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeedbackModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert_model = AutoModel.from_pretrained('../input/deberta-v3-base/deberta-v3-base')\n        self.fc = nn.Linear(self.bert_model.config.hidden_size, 3)\n        self.bn = nn.BatchNorm1d(3)\n        self._init_params()\n        \n        \n    def _init_params(self):\n        nn.init.xavier_normal_(self.fc.weight)\n        nn.init.constant_(self.fc.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n        \n    \n    def forward(self, input_ids):\n        attention_mask = (input_ids!=0).long()\n        x = self.bert_model(input_ids, attention_mask=attention_mask)\n        x = torch.sum(x.last_hidden_state * attention_mask.unsqueeze(-1), dim=1) / attention_mask.sum(dim=1, keepdims=True)\n        output = self.bn(self.fc(x))\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:34.268187Z","iopub.execute_input":"2022-06-10T10:33:34.268836Z","iopub.status.idle":"2022-06-10T10:33:34.281312Z","shell.execute_reply.started":"2022-06-10T10:33:34.268781Z","shell.execute_reply":"2022-06-10T10:33:34.280337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = FeedbackDataset(test, False)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:34.282925Z","iopub.execute_input":"2022-06-10T10:33:34.283579Z","iopub.status.idle":"2022-06-10T10:33:35.036199Z","shell.execute_reply.started":"2022-06-10T10:33:34.283522Z","shell.execute_reply":"2022-06-10T10:33:35.035235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\ntest_dataLoader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:35.038184Z","iopub.execute_input":"2022-06-10T10:33:35.039401Z","iopub.status.idle":"2022-06-10T10:33:35.095654Z","shell.execute_reply.started":"2022-06-10T10:33:35.039324Z","shell.execute_reply":"2022-06-10T10:33:35.084619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = 5\npred = []\nfor i in tqdm(range(folds)) : \n    checkpoint = torch.load(f'/kaggle/input/fb-debertav3base/checkpoint-{i + 1}.pt')\n    model = FeedbackModel().to(device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n    result = []\n    for input_ids in tqdm(test_dataLoader):\n        \n        with torch.no_grad():     \n            outputs = model(input_ids.to(device))\n        result.extend(F.softmax(outputs))    \n    pred.append(result)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:35.100524Z","iopub.execute_input":"2022-06-10T10:33:35.101193Z","iopub.status.idle":"2022-06-10T10:33:46.186306Z","shell.execute_reply.started":"2022-06-10T10:33:35.101145Z","shell.execute_reply":"2022-06-10T10:33:46.181153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = []\nfor pred1, pred2, pred3, pred4, pred5 in zip(pred[0], pred[1], pred[2], pred[3], pred[4]):\n    output.append(((pred1 + pred2 + pred3 + pred4 + pred5)/5).cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:46.187783Z","iopub.status.idle":"2022-06-10T10:33:46.194139Z","shell.execute_reply.started":"2022-06-10T10:33:46.193216Z","shell.execute_reply":"2022-06-10T10:33:46.193365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = np.array(output)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:46.197427Z","iopub.status.idle":"2022-06-10T10:33:46.199346Z","shell.execute_reply.started":"2022-06-10T10:33:46.19843Z","shell.execute_reply":"2022-06-10T10:33:46.198465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:46.202506Z","iopub.status.idle":"2022-06-10T10:33:46.203838Z","shell.execute_reply.started":"2022-06-10T10:33:46.203529Z","shell.execute_reply":"2022-06-10T10:33:46.20359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inef, adw, eff = [], [], []\nfor r1, r2, r3 in result:\n    inef.append(r1)\n    adw.append(r2)\n    eff.append(r3)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:46.206707Z","iopub.status.idle":"2022-06-10T10:33:46.207787Z","shell.execute_reply.started":"2022-06-10T10:33:46.207525Z","shell.execute_reply":"2022-06-10T10:33:46.207566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['Ineffective'] = inef\nsubmission['Adequate'] = adw\nsubmission['Effective'] = eff","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:46.210764Z","iopub.status.idle":"2022-06-10T10:33:46.212468Z","shell.execute_reply.started":"2022-06-10T10:33:46.212077Z","shell.execute_reply":"2022-06-10T10:33:46.212105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:46.215552Z","iopub.status.idle":"2022-06-10T10:33:46.216448Z","shell.execute_reply.started":"2022-06-10T10:33:46.216195Z","shell.execute_reply":"2022-06-10T10:33:46.216222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:33:46.219326Z","iopub.status.idle":"2022-06-10T10:33:46.221012Z","shell.execute_reply.started":"2022-06-10T10:33:46.220727Z","shell.execute_reply":"2022-06-10T10:33:46.220756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}